from __future__ import annotations

from typing import Any, Dict, List

import gradio as gr

from core.graph import build_graph
from core.state import AgentState

# ------------------------------
# LangGraph runnable ì¤€ë¹„
# ------------------------------

# ì•± ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ê·¸ë˜í”„ ì»´íŒŒì¼
graph = build_graph()


def _extract_attr(result: Any, name: str, default: Any):
    """
    resultê°€ dictì¼ ìˆ˜ë„ ìˆê³  AgentState ì¸ìŠ¤í„´ìŠ¤ì¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆ
    ë‘˜ ë‹¤ ëŒ€ì‘í•˜ê¸° ìœ„í•œ í—¬í¼ í•¨ìˆ˜.
    """
    if isinstance(result, dict):
        return result.get(name, default)
    # AgentState ê°™ì€ ê°ì²´ì¸ ê²½ìš°
    return getattr(result, name, default)


# ------------------------------
# Gradioì—ì„œ ì“°ëŠ” ì±„íŒ… í•¨ìˆ˜
# ------------------------------

def chat_fn(
    message: str,
    history: List[Dict[str, Any]] | None,
    tool_log_state: Any,
    rag_log_state: Any,
    memory_log_state: Any,
):
    """
    - message: ì‚¬ìš©ìê°€ ë°©ê¸ˆ ì…ë ¥í•œ í…ìŠ¤íŠ¸
    - history: ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” (Chatbotì´ ë“¤ê³  ìˆëŠ” messages)
    - tool_log_state, rag_log_state, memory_log_state:
        ì˜¤ë¥¸ìª½ JSON íŒ¨ë„ë“¤ì´ ë“¤ê³  ìˆëŠ” ìƒíƒœ
    """
    if history is None:
        history = []

    # ê³µë°± ì…ë ¥ì‹œ ê·¸ëƒ¥ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if not str(message).strip():
        return history, tool_log_state, rag_log_state, memory_log_state

    # 1) ìœ ì € ë©”ì‹œì§€ë¥¼ historyì— ì¶”ê°€
    updated_messages = history + [
        {"role": "user", "content": str(message)}
    ]

    # 2) LangGraphì— ë„˜ê¸¸ ì´ˆê¸° state êµ¬ì„±
    #    (tool_* / rag_* / reflection_* ì€ ê·¸ë˜í”„ ì•ˆì—ì„œ ì±„ì›Œì§ˆ ê²ƒ)
    state_dict: Dict[str, Any] = {
        "messages": updated_messages,
        "tool_calls": [],
        "tool_results": [],
        "rag_context": [],
        "reflection_notes": [],
    }

    # 3) LangGraph ì‹¤í–‰
    result = graph.invoke(state_dict)

    # 4) ê²°ê³¼ì—ì„œ ê° í•„ë“œë¥¼ êº¼ëƒ„
    raw_messages = _extract_attr(result, "messages", updated_messages)
    tool_calls = _extract_attr(result, "tool_calls", tool_log_state or [])
    rag_context = _extract_attr(result, "rag_context", rag_log_state or [])
    reflection_notes = _extract_attr(result, "reflection_notes", memory_log_state or [])

    # messagesì—ëŠ” LLM ì‘ë‹µê¹Œì§€ í¬í•¨ëœ ì „ì²´ ëŒ€í™”ê°€ ë“¤ì–´ìˆë‹¤ê³  ê°€ì •
    # (call_llm ë…¸ë“œê°€ state.messagesì— assistant ë©”ì‹œì§€ë¥¼ append í•˜ëŠ” êµ¬ì¡°)
    normalized_messages : List[Dict[str,str]] = []

    if isinstance(raw_messages, dict):
        raw_messages = [raw_messages]
    
    if not isinstance(raw_messages, list):
        normalized_messages.append(
            {"role": "assistant", "content": str(raw_messages)}
        )
    else:
        for m in raw_messages:
            if isinstance(m, dict) and "role" in m and "content" in m:
                normalized_messages.append(
                    {
                        "role" : str(m["role"]),
                        "content": str(m["content"]),
                    }
                )
            else:
                normalized_messages.append(
                    {
                        "role": "assistant",
                        "content": str(m),
                    }
                )

    # Chatbot, Tool ë¡œê·¸, RAG ë¡œê·¸, Memory ë¡œê·¸ë¥¼ í•œ ë²ˆì— ì—…ë°ì´íŠ¸
    return normalized_messages, tool_calls, rag_context, reflection_notes


# ------------------------------
# Gradio Blocks UI ì •ì˜
# ------------------------------

def create_gradio_app():
    """
    FastAPIì—ì„œ mountí•  Gradio Blocksë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜.
    """
    with gr.Blocks(title="LangGraph ReAct Agent") as demo:
        gr.Markdown(
            """
            # LangGraph ReAct Agent ğŸ¤– made by creAItion TEAM
            - LLM + Tool-calling + RAG + Memory + ReAct
            - ì•„ë˜ ì±„íŒ…ì°½ì— ì§ˆë¬¸ì„ ì…ë ¥í•´ë³´ì„¸ìš”.
            """
        )

        with gr.Row():
            # ------------------------------
            # ì™¼ìª½: ê¸°ë³¸ ì±—ë´‡ ì˜ì—­
            # ------------------------------
            with gr.Column(scale=3):
                chat = gr.Chatbot(
                    label="ReAct Agent Chat",
                    height=500,
                    value=[],  # ì´ˆê¸° ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ (ë¹„ì–´ìˆìŒ)
                )
                user_input = gr.Textbox(
                    label="ë©”ì‹œì§€ ì…ë ¥",
                    placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...",
                    lines=2,
                )
                send_btn = gr.Button("ì „ì†¡", variant="primary")

                # ------------------------------
                # ì˜¤ë¥¸ìª½: Tool / RAG / Memory ìƒíƒœ íŒ¨ë„
                # ------------------------------
            with gr.Column(scale=2):
                gr.Markdown("### ğŸ”§ Tool / RAG / Memory ìƒíƒœ")

                tool_log = gr.JSON(
                    label="Tool í˜¸ì¶œ ë¡œê·¸",
                    value=[],
                )
                rag_log = gr.JSON(
                    label="RAG ê²€ìƒ‰ ê²°ê³¼",
                    value=[],
                )
                memory_log = gr.JSON(
                    label="Memory / Reflection ìƒíƒœ",
                    value=[],
                )

        # ------------------------------
        # ì´ë²¤íŠ¸ ì—°ê²°
        # ------------------------------

        # Enterë¡œ ì „ì†¡
        user_input.submit(
            fn=chat_fn,
            inputs=[user_input, chat, tool_log, rag_log, memory_log],
            outputs=[chat, tool_log, rag_log, memory_log],
        )

        # ë²„íŠ¼ í´ë¦­ìœ¼ë¡œ ì „ì†¡
        send_btn.click(
            fn=chat_fn,
            inputs=[user_input, chat, tool_log, rag_log, memory_log],
            outputs=[chat, tool_log, rag_log, memory_log],
        )

        return demo


if __name__ == "__main__":
    app = create_gradio_app()
    app.launch(server_name="0.0.0.0", server_port=7860)
